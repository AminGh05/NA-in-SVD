{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proving the Singular Value Decomposition (SVD) Formula Using Numerical Analysis\n",
    "\n",
    "This notebook provides a complete proof that any matrix $A \\in \\mathbb{R}^{m \\times n}$ can be decomposed as $A = U \\Sigma V^T$, where $U$ is an $m \\times m$ orthogonal matrix, $\\Sigma$ is an $m \\times n$ diagonal matrix with non-negative singular values, and $V$ is an $n \\times n$ orthogonal matrix. The proof combines linear algebra with numerical analysis principles, ensuring computational feasibility.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. SVD Definition\n",
    "\n",
    "The SVD of a matrix $A \\in \\mathbb{R}^{m \\times n}$ is:\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "- **$U \\in \\mathbb{R}^{m \\times m}$**: Orthogonal ($U^T U = UU^T = I_m$).\n",
    "- **$\\Sigma \\in \\mathbb{R}^{m \\times n}$**: Diagonal, with non-negative singular values $\\sigma_1 \\geq \\sigma_2 \\geq \\cdots \\geq \\sigma_r \\geq 0$, where $r = \\text{rank}(A)$.\n",
    "- **$V \\in \\mathbb{R}^{n \\times n}$**: Orthogonal ($V^T V = VV^T = I_n$).\n",
    "\n",
    "**Goal**: Prove this decomposition exists and can be computed numerically.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Theoretical Foundation\n",
    "\n",
    "The SVD is based on the eigenvalue decomposition of symmetric matrices $A^T A$ and $A A^T$.\n",
    "\n",
    "### 2.1 Properties of $A^T A$ and $A A^T$\n",
    "- **$A^T A \\in \\mathbb{R}^{n \\times n}$** (S<sub>right</sub>): Symmetric ($(A^T A)^T = A^T A$) and positive semi-definite ($x^T (A^T A) x = \\|Ax\\|^2 \\geq 0$).\n",
    "- **$A A^T \\in \\mathbb{R}^{m \\times m}$** (S<sub>left</sub>): Symmetric and positive semi-definite.\n",
    "- **Spectral Theorem**: Both matrices have real eigenvalues and orthonormal eigenvectors.\n",
    "\n",
    "Note: We call eigenvectors of S<sub>left</sub> the Left Singular vectors and eigenvectors of S<sub>right</sub> the Right Singular vectors.\n",
    "\n",
    "### 2.2 Eigenvalue Connection\n",
    "- Eigenvalues of $A^T A$: $\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_n \\geq 0$.\n",
    "- Singular values of $A$: $\\sigma_i = \\sqrt{\\lambda_i}$ for $i = 1, \\ldots, r$, where $r \\leq \\min(m, n)$.\n",
    "- Non-zero eigenvalues of $A^T A$ and $A A^T$ are the same.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Constructing the SVD\n",
    "\n",
    "We construct $U$, $\\Sigma$, and $V$ explicitly to show $A = U \\Sigma V^T$.\n",
    "\n",
    "### 3.1 Compute Eigenvectors and Eigenvalues of $A^T A$\n",
    "- Form $A^T A$.\n",
    "- Compute eigenvalues $\\lambda_1 \\geq \\cdots \\geq \\lambda_n \\geq 0$ and orthonormal eigenvectors $v_1, \\ldots, v_n$.\n",
    "- Singular values: $\\sigma_i = \\sqrt{\\lambda_i}$, with $\\sigma_i = 0$ for $i > r$.\n",
    "- Form $V = [v_1, \\ldots, v_n]$, so $V^T V = I_n$.\n",
    "\n",
    "$$\n",
    "A^T A v_i = \\sigma_i^2 v_i\n",
    "$$\n",
    "\n",
    "### 3.2 Construct $U$\n",
    "- For each non-zero $\\sigma_i$ ($i = 1, \\ldots, r$):\n",
    "$$\n",
    "u_i = \\frac{1}{\\sigma_i} A v_i\n",
    "$$\n",
    "- Verify orthonormality:\n",
    "$$\n",
    "u_i^T u_j = \\frac{1}{\\sigma_i \\sigma_j} v_i^T A^T A v_j = \\frac{1}{\\sigma_i \\sigma_j} v_i^T (\\sigma_j^2 v_j) = \\delta_{ij}\n",
    "$$\n",
    "- If $m > r$, extend $\\{u_1, \\ldots, u_r\\}$ to an orthonormal basis for $\\mathbb{R}^m$ using Gram-Schmidt.\n",
    "- Form $U = [u_1, \\ldots, u_m]$, so $U^T U = I_m$.\n",
    "\n",
    "### 3.3 Construct $\\Sigma$\n",
    "- Define $\\Sigma \\in \\mathbb{R}^{m \\times n}$:\n",
    "$$\n",
    "\\Sigma_{ij} = \\begin{cases} \n",
    "\\sigma_i & \\text{if } i = j \\leq r \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 3.4 Verify the Decomposition\n",
    "- Check $A = U \\Sigma V^T$:\n",
    "  - For $i = 1, \\ldots, r$:\n",
    "    $$\n",
    "    A v_i = \\sigma_i u_i, \\quad U \\Sigma V^T v_i = U \\Sigma e_i = \\sigma_i u_i\n",
    "    $$\n",
    "  - For $i > r$, $A v_i = 0$, and $U \\Sigma V^T v_i = 0$.\n",
    "- Since $\\{v_i\\}$ is a basis for $\\mathbb{R}^n$, $A = U \\Sigma V^T$.\n",
    "\n",
    "### 3.5 Orthogonality of $U$\n",
    "- Alternatively, verify $u_i$ are eigenvectors of $A A^T$:\n",
    "$$\n",
    "A A^T u_i = A (\\sigma_i v_i) = \\sigma_i A v_i = \\sigma_i^2 u_i\n",
    "$$\n",
    "- This confirms $u_i$ correspond to eigenvalues $\\sigma_i^2$, ensuring consistency.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Numerical Computation\n",
    "\n",
    "The SVD is computed using stable numerical algorithms.\n",
    "\n",
    "### 4.1 QR Algorithm\n",
    "\n",
    "It is used to measure the eigenvalues.\n",
    "\n",
    "- **Steps**:\n",
    "  1. Start with $B_0 = A^T A$.\n",
    "  2. Iterate: $B_k = Q_k R_k$, $B_{k+1} = R_k Q_k$.\n",
    "  3. $B_k \\to \\text{diagonal}(\\lambda_1, \\ldots, \\lambda_n)$, with $V$ from accumulated $Q_k$.\n",
    "- **Stability**: Orthogonal transformations ensure error $O(\\epsilon \\|A\\|_2)$.\n",
    "\n",
    "### 4.2 Other Methods\n",
    "- **Golub-Kahan Bidiagonalization**: Reduces $A$ to bidiagonal form, then applies QR.\n",
    "- **Divide-and-Conquer**: Splits matrix for efficiency, used in LAPACK.\n",
    "- **Jacobi Method**: Applies rotations, suitable for parallelization.\n",
    "\n",
    "### 4.3 Larger Matrices\n",
    "- **Numerical methods**: We use numerical methods like Newton's to find solutions to equations of eigenvalues.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Numerical Example\n",
    "\n",
    "Consider $A = \\begin{bmatrix} 3 & 0 \\\\ 4 & 5 \\end{bmatrix}$.\n",
    "\n",
    "### 5.1 Compute $A^T A$\n",
    "$$\n",
    "A^T A = \\begin{bmatrix} 25 & 20 \\\\ 20 & 25 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### 5.2 Eigenvalues\n",
    "$$\n",
    "\\det(A^T A - \\lambda I) = (25 - \\lambda)^2 - 400 = (\\lambda - 45)(\\lambda - 5)\n",
    "$$\n",
    "- Eigenvalues: $\\lambda_1 = 45$, $\\lambda_2 = 5$.\n",
    "- Singular values: $\\sigma_1 = \\sqrt{45} \\approx 6.7082$, $\\sigma_2 = \\sqrt{5} \\approx 2.2361$.\n",
    "\n",
    "### 5.3 Eigenvectors\n",
    "- For $\\lambda_1 = 45$: Eigenvector $v_1 = \\frac{1}{\\sqrt{2}} [1, 1]$.\n",
    "- For $\\lambda_2 = 5$: Eigenvector $v_2 = \\frac{1}{\\sqrt{2}} [1, -1]$.\n",
    "- Form $V = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$.\n",
    "\n",
    "### 5.4 Compute $U$\n",
    "- For $\\sigma_1$:\n",
    "$$\n",
    "A v_1 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 3 \\\\ 9 \\end{bmatrix}, \\quad u_1 = \\frac{1}{\\sqrt{45}} \\cdot \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 3 \\\\ 9 \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{10}}{10} \\\\ \\frac{3\\sqrt{10}}{10} \\end{bmatrix}\n",
    "$$\n",
    "- For $\\sigma_2$:\n",
    "$$\n",
    "A v_2 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 3 \\\\ -1 \\end{bmatrix}, \\quad u_2 = \\frac{1}{\\sqrt{5}} \\cdot \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 3 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} \\frac{3\\sqrt{10}}{10} \\\\ -\\frac{\\sqrt{10}}{10} \\end{bmatrix}\n",
    "$$\n",
    "- Form $U = \\begin{bmatrix} \\frac{\\sqrt{10}}{10} & \\frac{3\\sqrt{10}}{10} \\\\ \\frac{3\\sqrt{10}}{10} & -\\frac{\\sqrt{10}}{10} \\end{bmatrix}$.\n",
    "\n",
    "### 5.5 Form $\\Sigma$\n",
    "$$\n",
    "\\Sigma = \\begin{bmatrix} \\sqrt{45} & 0 \\\\ 0 & \\sqrt{5} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### 5.6 Verification\n",
    "- Compute $U \\Sigma V^T$ and confirm it equals $A$ (can be done numerically in Python).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Numerical Stability\n",
    "- **Condition Number**: Affects accuracy for small $\\sigma_i$.\n",
    "- **Error Bounds**: Algorithms achieve errors $O(\\epsilon \\|A\\|_2)$.\n",
    "- **Libraries**: LAPACK, NumPy, MATLAB use optimized implementations.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conclusion\n",
    "The SVD is proven because:\n",
    "- **Existence**: Guaranteed by eigenvalue decomposition of $A^T A$ and $A A^T$.\n",
    "- **Construction**: $V$, $U$, and $\\Sigma$ are explicitly derived.\n",
    "- **Verification**: $A = U \\Sigma V^T$ holds for all basis vectors.\n",
    "- **Numerical Feasibility**: Stable algorithms ensure practical computation.\n",
    "\n",
    "This completes the proof. For implementation, see numerical libraries or request a Python example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2x2 Matrix A:\n",
      "[[4 2]\n",
      " [1 3]]\n",
      "\n",
      "Singular values (Newton method): [5.11667274 1.95439508]\n",
      "Singular values (NumPy SVD):     [5.11667274 1.95439508]\n",
      "Difference (|NumPy - Newton|):    [8.8817842e-16 4.4408921e-16]\n",
      "\n",
      "3x3 Matrix B:\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "Singular values (via NumPy): [3. 2. 1.]\n",
      "Left singular vectors (U):\n",
      " [[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "Right singular vectors (V^T):\n",
      " [[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -----------Part 1: 2x2 Matrix A -----------\n",
    "A = np.array([[4, 2],\n",
    "              [1, 3]])\n",
    "\n",
    "# Compute A^T A\n",
    "ATA = A.T @ A\n",
    "\n",
    "# Characteristic polynomial of ATA: λ^2 - trace*λ + det = 0\n",
    "a = 1\n",
    "b = -np.trace(ATA)\n",
    "c = np.linalg.det(ATA)\n",
    "\n",
    "# Define polynomial and derivative for Newton\n",
    "def f(lmbda):\n",
    "    return a * lmbda**2 + b * lmbda + c\n",
    "\n",
    "def df(lmbda):\n",
    "    return 2 * a * lmbda + b\n",
    "\n",
    "# Newton's method\n",
    "def newton_method(f, df, x0, tol=1e-10, max_iter=100):\n",
    "    x = x0\n",
    "    for _ in range(max_iter):\n",
    "        x_new = x - f(x) / df(x)\n",
    "        if abs(x_new - x) < tol:\n",
    "            return x_new\n",
    "        x = x_new\n",
    "    raise ValueError(\"Did not converge\")\n",
    "\n",
    "# Use Newton's method to get eigenvalues of A^T A\n",
    "lambda1 = newton_method(f, df, x0=1.0)\n",
    "lambda2 = newton_method(f, df, x0=100.0)\n",
    "\n",
    "# Singular values (via Newton)\n",
    "sigma_newton = np.sort(np.sqrt([lambda1, lambda2]))[::-1]\n",
    "\n",
    "# Singular values (via NumPy)\n",
    "_, sigma_numpy, _ = np.linalg.svd(A)\n",
    "sigma_numpy = np.sort(sigma_numpy)[::-1]\n",
    "\n",
    "# Comparison\n",
    "diff = np.abs(sigma_numpy - sigma_newton)\n",
    "\n",
    "# ----------- Output -----------\n",
    "print(\"2x2 Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nSingular values (Newton method):\", sigma_newton)\n",
    "print(\"Singular values (NumPy SVD):    \", sigma_numpy)\n",
    "print(\"Difference (|NumPy - Newton|):   \", diff)\n",
    "\n",
    "# ----------- PART 2: 3x3 Matrix with NumPy SVD -----------\n",
    "\n",
    "B = np.array([[1, 0, 0],\n",
    "              [0, 2, 0],\n",
    "              [0, 0, 3]])\n",
    "\n",
    "U, S, VT = np.linalg.svd(B)\n",
    "\n",
    "print(\"\\n3x3 Matrix B:\")\n",
    "print(B)\n",
    "print(\"Singular values (via NumPy):\", S)\n",
    "print(\"Left singular vectors (U):\\n\", U)\n",
    "print(\"Right singular vectors (V^T):\\n\", VT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
